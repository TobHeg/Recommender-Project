{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # to extract data from web\n",
    "import requests # to pull website\n",
    "import pandas as pd # to build dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select website to scrap\n",
    "url='https://www.billboard.com/charts/hot-100/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download html with a get request\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse html (create the 'soup')\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Build DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title list from h3\n",
    "title=[]\n",
    "for i in soup.select('li.o-chart-results-list__item h3'):\n",
    "    title.append(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean from /n\n",
    "clean_title_list = []\n",
    "for element in title:\n",
    "\n",
    "    clean_title_list.append(element.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the other info into one big list\n",
    "big_list=[]\n",
    "for i in soup.select('li.o-chart-results-list__item span'):\n",
    "    big_list.append(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean from /n\n",
    "clean_big_list = []\n",
    "for element in big_list:\n",
    "\n",
    "    clean_big_list.append(element.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 'New' and 'Re-Enter' as it screws with the order of elements\n",
    "\n",
    "while 'NEW' in clean_big_list:\n",
    "    clean_big_list.remove('NEW')\n",
    "while 'RE-\\nENTER' in clean_big_list:\n",
    "    clean_big_list.remove('RE-\\nENTER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally fill all the lists\n",
    "rank = clean_big_list[0::8]\n",
    "artist = clean_big_list[1::8]\n",
    "last_week = clean_big_list[2::8]\n",
    "peak_pos = clean_big_list[3::8]\n",
    "wks_on_chart = clean_big_list[4::8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary out of the lists\n",
    "dic = {'Rank':rank,'Artist':artist,'Title':clean_title_list,'Last Week':last_week,'Peak Position':peak_pos,'Weeks on Chart':wks_on_chart}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataframe out of the Dictionary\n",
    "df = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine title and artist into one column\n",
    "df['title_artist'] = df['Title'].str.cat(others=df['Artist'],sep='  BY  ')\n",
    "# make lower case\n",
    "df['title_artist'] = df['title_artist'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Output into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/Top100.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c829346dbfeebf68e991a09823a010cd364a5faadbed445a3ecf1e247d421bf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
